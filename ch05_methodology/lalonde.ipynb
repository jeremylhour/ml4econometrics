{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5.5: Empirical application, job training program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import PolynomialFeatures, MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegressionCV, LassoCV\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "\n",
    "from ml4econometrics.ols import OLS\n",
    "from ml4econometrics.penalized_regressions import Lasso, LogitLasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------\n",
    "# ATT function\n",
    "#------------------------------------------------------\n",
    "def att(y, d, y_hat, d_hat, group_idx=None):\n",
    "    \"\"\"\n",
    "    att:\n",
    "        Compute average treatment effect estimator,\n",
    "        and its standard error.\n",
    "    Args:\n",
    "        y (np.array): outcome.\n",
    "        d (np.array): Treatment status.\n",
    "        y_hat (np.array): Prediction of Y from X.\n",
    "        d_hat (np.array): Propensity score.\n",
    "        group_idx (np.array): Group indicator.\n",
    "    \"\"\"\n",
    "    gamma = np.empty_like(y)\n",
    "    if group_idx is not None:\n",
    "        y = y[group_idx]\n",
    "        d = d[group_idx]\n",
    "        y_hat = y_hat[group_idx]\n",
    "        d_hat = d_hat[group_idx]\n",
    "\n",
    "    pi = d.mean()\n",
    "    gamma[group_idx] = (d - (1 - d) * d_hat / (1 - d_hat)) * (y - y_hat) / pi\n",
    "    gamma[~group_idx] = np.nan\n",
    "    return gamma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLUMNS = [\n",
    "    \"treated\",\n",
    "    \"age\",\n",
    "    \"education\",\n",
    "    \"black\",\n",
    "    \"hispanic\",\n",
    "    \"married\",\n",
    "    \"nodegree\",\n",
    "    \"re74\",\n",
    "    \"re75\",\n",
    "    \"re78\",\n",
    "]\n",
    "\n",
    "COVARIATES = [\"age\", \"education\", \"black\", \"hispanic\", \"married\", \"nodegree\", \"re74\", \"re75\"]\n",
    "\n",
    "FILES = {\n",
    "    \"treated\": \"http://www.nber.org/~rdehejia/data/nswre74_treated.txt\",\n",
    "    \"experimental\": \"http://www.nber.org/~rdehejia/data/nswre74_control.txt\",\n",
    "    \"psid\": \"http://www.nber.org/~rdehejia/data/psid_controls.txt\"\n",
    "}\n",
    "\n",
    "df = pd.concat([\n",
    "    (\n",
    "        pd.read_csv(v, sep=r\"\\s+\", names=COLUMNS)\n",
    "        .assign(sample = k)\n",
    "        .assign(noincome74 = lambda x: 1*(x[\"re74\"] == 0))\n",
    "        .assign(noincome75 = lambda x: 1*(x[\"re75\"] == 0))\n",
    "        ) for k, v in FILES.items()\n",
    "], axis=0).reset_index(drop=True)\n",
    "\n",
    "df[\"sample\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline: experimental estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.query(\"sample in ('treated', 'experimental')\")[\"re78\"].values\n",
    "d = df.query(\"sample in ('treated', 'experimental')\")[\"treated\"].values\n",
    "\n",
    "ols = OLS()\n",
    "ols.fit(d.reshape(-1, 1), y)\n",
    "ols.compute_std(d.reshape(-1, 1), y, robust=False)\n",
    "\n",
    "print(f\"Experimental estimate is {ols.coef_[0]:.2f} USD with an std of {ols.std[1]:.2f} USD.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = ColumnTransformer([\n",
    "    (\n",
    "        'continuous',\n",
    "        Pipeline([\n",
    "            (\"polynomial\", PolynomialFeatures(degree=5)),\n",
    "            (\"min_max_scaler\", MinMaxScaler())\n",
    "        ]),\n",
    "        [\"age\", \"education\", \"re74\", \"re75\"]\n",
    "    ),\n",
    "    (\n",
    "        'interactions',\n",
    "        Pipeline([\n",
    "            (\"polynomial\", PolynomialFeatures(degree=2, interaction_only=True)),\n",
    "            (\"min_max_scaler\", MinMaxScaler())\n",
    "        ]),\n",
    "        COVARIATES\n",
    "    )\n",
    "])\n",
    "X = pipe.fit_transform(df.query(\"sample in ('treated', 'psid')\"))\n",
    "print(f\"Shape after transformation: {X.shape}.\")\n",
    "\n",
    "X = X[:, X.std(axis=0) != 0]\n",
    "print(f\"Shape after removing constant features: {X.shape}.\")\n",
    "\n",
    "u, w, vt = np.linalg.svd(X)\n",
    "e_ = w ** 2\n",
    "e_ /= e_.sum()\n",
    "\n",
    "_ = plt.hist(e_, bins=30, log=True)\n",
    "plt.title(\"Histogram of feature eigenvalues (log scale)\")\n",
    "print(f\"Number of zero singular values: {(e_==0).sum():.0f}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.query(\"sample in ('treated', 'psid')\")[\"re78\"].values\n",
    "d = df.query(\"sample in ('treated', 'psid')\")[\"treated\"].astype(\"int\").values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(X)\n",
    "n_folds = 5   # nb folds\n",
    "np.random.seed(99999)\n",
    "\n",
    "# Generate random split\n",
    "cvgroup = np.digitize(np.random.rand(n), np.linspace(0, 1, n_folds + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators ={\n",
    "    \"lasso bch\": {\n",
    "        \"treatment\": Lasso(bch_penalty=True, max_iter=10_000),\n",
    "        \"outcome\": Lasso(bch_penalty=True, max_iter=10_000)\n",
    "    },\n",
    "    \"lasso cv\": {\n",
    "        \"treatment\": LogisticRegressionCV(max_iter=5_000),\n",
    "        \"outcome\": LassoCV(max_iter=5_000)\n",
    "    },\n",
    "    \"random forest\": {\n",
    "        \"treatment\": RandomForestRegressor(n_estimators=500, min_samples_split=5),\n",
    "        \"outcome\": RandomForestRegressor(n_estimators=500, min_samples_split=5)\n",
    "    },\n",
    "    \"gradient boosting\": {\n",
    "        \"treatment\": GradientBoostingRegressor(n_estimators=500, min_samples_split=5),\n",
    "        \"outcome\": GradientBoostingRegressor(n_estimators=500, min_samples_split=5)\n",
    "    },\n",
    "}\n",
    "\n",
    "estimators = {\"lasso bch\": estimators[\"lasso bch\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double ML with cross-fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = {}\n",
    "for k in tqdm(range(1, n_folds + 1)):\n",
    "    Ik = (cvgroup == k)\n",
    "    NIk = (cvgroup != k)\n",
    "\n",
    "    # Fit\n",
    "    for method, v in estimators.items():\n",
    "        v[\"treatment\"].fit(X[NIk], d[NIk])\n",
    "        if hasattr(v[\"treatment\"], \"predict_proba\"):\n",
    "            d_hat = v[\"treatment\"].predict_proba(X[Ik])[:, 1]\n",
    "        else:\n",
    "            d_hat = v[\"treatment\"].predict(X[Ik])\n",
    "        cs = (d_hat >= .01) & (d_hat <= .99)\n",
    "\n",
    "        v[\"outcome\"].fit(X[NIk], y[NIk])\n",
    "        y_hat = v[\"treatment\"].predict(X[Ik])\n",
    "\n",
    "        if k == 1:\n",
    "            gamma[method] = [att(y[Ik], d[Ik], y_hat, d_hat, group_idx=cs)]\n",
    "        else:\n",
    "            gamma[method].append(att(y[Ik], d[Ik], y_hat, d_hat, group_idx=cs))\n",
    "\n",
    "gamma = pd.DataFrame({k: np.concatenate(v) for k, v in gamma.items()})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = {\n",
    "    'ATT': gamma.mean(),\n",
    "    'std': gamma.std() / np.sqrt(gamma.notna().sum()),\n",
    "    'effective sample size': gamma.notna().sum()\n",
    "}\n",
    "\n",
    "pd.DataFrame(table).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml4econometrics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
